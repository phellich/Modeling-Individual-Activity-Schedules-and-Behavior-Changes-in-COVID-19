{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL = 'Avenches'\n",
    "LOCAL = 'Lausanne'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(df, column, fraction):\n",
    "    \"\"\"\n",
    "    Perform stratified sampling on df based on column.\n",
    "    :param df: Input dataframe\n",
    "    :param column: Column name for stratification\n",
    "    :param fraction: Fraction of rows to sample from each group\n",
    "    :return: Sampled dataframe\n",
    "    \"\"\"\n",
    "    return df.groupby(column).apply(lambda x: x.sample(frac=fraction)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_horizon(t):\n",
    "    \"\"\" Help to round a time to 5m intervals \"\"\"\n",
    "    # Convert datetime.time to datetime.datetime for calculations\n",
    "    dt = datetime.combine(datetime.today(), t)\n",
    "    \n",
    "    # Find the number of seconds since midnight\n",
    "    seconds_since_midnight = (dt - dt.replace(hour=0, minute=0, second=0, microsecond=0)).seconds\n",
    "\n",
    "    # Round to the closest 5 minutes (300 seconds)\n",
    "    rounded_seconds = round(seconds_since_midnight / 300) * 300\n",
    "    rounded_dt = dt.replace(hour=0, minute=0, second=0) + timedelta(seconds=rounded_seconds)\n",
    "\n",
    "    return rounded_dt.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_horizon_interval(t):\n",
    "    \"\"\" Return time horizon corresponding to a timestamp \"\"\"\n",
    "    rounded_time = round_to_horizon(t)\n",
    "    \n",
    "    # Convert datetime.time to datetime.datetime for calculations\n",
    "    dt = datetime.combine(datetime.today(), rounded_time)\n",
    "    \n",
    "    # Get total minutes since midnight\n",
    "    minutes_since_midnight = (dt - dt.replace(hour=0, minute=0, second=0)).seconds // 60\n",
    "\n",
    "    # Convert total minutes to horizon intervals (5 minute intervals)\n",
    "    horizon_interval = minutes_since_midnight // 5\n",
    "\n",
    "    return horizon_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time(value):\n",
    "    \"\"\" Check that all time values are correct (hours<24)\"\"\"\n",
    "    try:\n",
    "        # Try converting the value to datetime and extract the time\n",
    "        return pd.to_datetime(value).time()\n",
    "    except:\n",
    "        # Return a placeholder for out-of-range values\n",
    "        return \"out_of_range\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preferences(id, type, df):\n",
    "    ''' Returns the duration and starting preference for an individual and an activity'''\n",
    "    row = df.loc[(df['id'] == id) & (df['type'] == type)]\n",
    "    \n",
    "    if row.empty:\n",
    "        return default_durations[type], default_starting[type]\n",
    "    else:\n",
    "        # Assuming there's only one matching row, so taking the first one\n",
    "        duration = row['duration_interval'].iloc[0]\n",
    "        starting_time = row['start_time_interval'].iloc[0]\n",
    "        return duration, starting_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data and filter the irrelevants columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file paths\n",
    "activity_file = 'data_original/vaud_activities.csv.gz'\n",
    "population_file = 'data_original/vaud_population.csv.gz'\n",
    "trip_file = 'data_original/vaud_trips.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV files\n",
    "def read_gzipped_csv(file_path):\n",
    "    with gzip.open(file_path, 'rt') as file:\n",
    "        df = pd.read_csv(file)\n",
    "    return df\n",
    "\n",
    "# Read the dataframes\n",
    "activity_vaud = read_gzipped_csv(activity_file)\n",
    "population_vaud = read_gzipped_csv(population_file)[['id', 'age', 'home_x', 'home_y', 'local']].drop_duplicates()\n",
    "trip_vaud = read_gzipped_csv(trip_file)[['Unnamed: 0', 'id', 'mode', 'dep_time','trav_time','start_link','end_link']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the population by the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_local = population_vaud[population_vaud['local'] == LOCAL] # individual id deja uniques\n",
    "# print(len(population_local))\n",
    "# population_local.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the filtered population to extract activities of the same city. Also count the activities by type in this city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_local_ids = population_local['id'].unique()\n",
    "activity_local = activity_vaud[activity_vaud['id'].isin(population_local_ids)]\n",
    "activity_local_filt = activity_local[~activity_local['type'].isin(['other', 'pt interaction', 'home'])] # peut etre besoin du home facilities id ? \n",
    "# count_act_by_types = activity_local_filt.groupby('type')['facility'].nunique().reset_index()\n",
    "# print(f\"Here's the count of facilities by types in {LOCAL} : {count_act_by_types}\")\n",
    "# print(len(activity_local_filt))\n",
    "# activity_local_filt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the activities of this city by keeping the proportion between each type (stratified sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peut etre associer un seed pour avoir toujours le meme resultat ? \n",
    "# Attention : stratified sampling != proportional sampling \n",
    "activity_local_filt_sampled = stratified_sample(activity_local_filt, 'type', 0.0001) # 0.001 to compare exact / heuristic\n",
    "# activity_local_filt_sampled.drop(columns=['start_time', 'end_time'], inplace=True)\n",
    "# print(len(activity_local_filt))\n",
    "# print(len(activity_local_filt_sampled))\n",
    "# count_act_by_types_sampled = activity_local_filt_sampled.groupby('type')['facility'].nunique().reset_index()\n",
    "# print(f\"Here's the count of facilities by types in the sample : {count_act_by_types_sampled}\")\n",
    "# activity_local_filt_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new columns for each activity with their caracterics (anticipate initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = 00:00 // 288 = 24:00 (total len = 289)\n",
    "# Code to fix the following values for each activity type : \n",
    "    # t1 = earliest time to start\n",
    "    # t2 = latest time to start\n",
    "    # t3 = max duration\n",
    "    # min duration\n",
    "    # des duration\n",
    "\n",
    "for i, row in activity_local_filt_sampled.iterrows():\n",
    "    type_ = row['type']\n",
    "    match type_: \n",
    "        case 'education':\n",
    "            # activity_local_filt_sampled.at[i, 'feasible_start'] = pd.to_datetime('07:00:00')\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 1\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 84 # 7h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 276 # 23h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 132 # 11h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 6 # 30m\n",
    "            # activity_local_filt_sampled.at[i, 'des_duration'] = randint(12, 60) # entre 1h et 5h\n",
    "        case 'work':\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 2\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 60 # 5h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 276 # 23h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 132 # 11h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 6 # 30m\n",
    "            # activity_local_filt_sampled.at[i, 'des_duration'] = randint(24, 60) # entre 2h et 5h\n",
    "        case 'leisure':\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 3\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 0 # 0h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 276 # 23h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 132 # 11h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 6 # 30m\n",
    "            # activity_local_filt_sampled.at[i, 'des_duration'] = randint(12, 60) # entre 1h et 5h\n",
    "        case 'shop':\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 4\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 84 # 7h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 240 # 20h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 132 # 11h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 6 # 30m\n",
    "            # activity_local_filt_sampled.at[i, 'des_duration'] = randint(12, 60) # entre 1h et 5h\n",
    "            \n",
    "# int_columns = ['earliest_start', 'latest_start', 'max_duration', 'min_duration', 'des_duration', 'x', 'y', 'group']\n",
    "int_columns = ['earliest_start', 'latest_start', 'max_duration', 'min_duration', 'x', 'y', 'group']\n",
    "activity_local_filt_sampled[int_columns] = activity_local_filt_sampled[int_columns].astype(int) \n",
    "\n",
    "# Proof that we have a activity id : \n",
    "# print(len(activity_local_filt_sampled))\n",
    "# print(activity_local_filt_sampled.index.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the individuals among the city inhabitants and converts home coordinates in `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_local_sample = population_local.sample(frac = 0.0001)\n",
    "int_columns_2 = ['home_x', 'home_y'] \n",
    "population_local_sample[int_columns_2] = population_local_sample[int_columns_2].astype(int) \n",
    "# print(len(population_local))\n",
    "# print(len(population_local_sample))\n",
    "# population_local_sample.head(1)\n",
    "# activity_local_filt_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter invalid times (hours < 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN ONCE !!! 2m17 si 0.0001 de lausanne\n",
    "# Convert 'start_time' and 'end_time' columns to datetime.time format : JUST RUN ONCE\n",
    "activity_local_filt['start_time'] = activity_local_filt['start_time'].apply(convert_to_time)\n",
    "activity_local_filt['end_time'] = activity_local_filt['end_time'].apply(convert_to_time)\n",
    "\n",
    "# Filter out rows with \"out_of_range\" value\n",
    "activity_local_filt = activity_local_filt[\n",
    "    (activity_local_filt['start_time'] != \"out_of_range\") & \n",
    "    (activity_local_filt['end_time'] != \"out_of_range\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert time object in terms of horizons  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_local_filt['start_time_interval'] = activity_local_filt['start_time'].apply(time_to_horizon_interval)\n",
    "activity_local_filt['end_time_interval'] = activity_local_filt['end_time'].apply(time_to_horizon_interval)\n",
    "activity_local_filt['duration_interval'] = activity_local_filt['end_time_interval'] - activity_local_filt['start_time_interval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each individual, and for each activity type, add starting time and duration preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity_local_filt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population_local_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_of_interessed = activity_local_filt[activity_local_filt['id'].isin(population_local_sample['id'])]\n",
    "# rows_of_interessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shop': 163, 'leisure': 180, 'work': 119, 'education': 126}\n",
      "{'shop': 6, 'leisure': 20, 'work': 65, 'education': 46}\n"
     ]
    }
   ],
   "source": [
    "# valeurs par default : c'est facile de faire la moyenne des time horizon pour type (starting et duration) !\n",
    "# default_durations = {'shop': 216, 'leisure': 216, 'work': 108, 'education': 108}\n",
    "# default_starting = {'shop': 12, 'leisure': 12, 'work': 48, 'education': 48}\n",
    "# default_durations = {'shop': 0, 'leisure': 0, 'work': 0, 'education': 0}\n",
    "# default_starting = {'shop': 0, 'leisure': 0, 'work': 0, 'education': 0}\n",
    "\n",
    "default_durations = {}\n",
    "default_starting = {}\n",
    "facility_types = ['shop', 'leisure', 'work', 'education']\n",
    "for facility in facility_types: \n",
    "    temp_df = activity_local_filt[activity_local_filt['type'] == facility]\n",
    "    default_durations[facility] = int(np.floor(temp_df['duration_interval'].mean()))\n",
    "    default_starting[facility] = int(np.floor(temp_df['start_time_interval'].mean()))\n",
    "    \n",
    "print(default_starting)\n",
    "print(default_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 79.36it/s]\n"
     ]
    }
   ],
   "source": [
    "facility_types = ['shop', 'leisure', 'work', 'education']\n",
    "for facility in tqdm(facility_types): \n",
    "    # function extracts both duration and starting time preferences and assigns them\n",
    "    preferences = population_local_sample.apply(\n",
    "        lambda row: get_preferences(row['id'], facility, rows_of_interessed), axis=1\n",
    "    )\n",
    "    \n",
    "    population_local_sample[f'{facility}_duration'] = preferences.apply(lambda x: x[0])\n",
    "    population_local_sample[f'{facility}_starting'] = preferences.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population_local_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the final preprocessed dataframes into .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_local_filt_sampled.to_csv(f'data_preprocessed/activity.csv', index=False)\n",
    "population_local_sample.to_csv(f'data_preprocessed/population.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST CODE TO REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with start_link\n",
    "trip_local_merged = pd.merge(trip_local, link_df, left_on='start_link', right_index=True)\n",
    "trip_local_merged.rename(columns={'x': 'start_x', 'y': 'start_y'}, inplace=True)\n",
    "\n",
    "# merge with end_link\n",
    "trip_local_merged = pd.merge(trip_local_merged, link_df, left_on='end_link', right_index=True)\n",
    "trip_local_merged.rename(columns={'x': 'end_x', 'y': 'end_y'}, inplace=True)\n",
    "\n",
    "trip_local_merged.head()\n",
    "\n",
    "# pour chaque tripreer une nouvelle colonne avcec direct la distance calcule from le df des activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_local_merged['distance'] = np.sqrt((trip_local_merged['start_x'] - trip_local_merged['end_x']) ** 2 +\n",
    "                                (trip_local_merged['start_y'] - trip_local_merged['end_y']) ** 2)\n",
    "# Ensure that trav_time is in timedelta format\n",
    "trip_local_merged['trav_time'] = pd.to_timedelta(trip_local_merged['trav_time'])\n",
    "\n",
    "average_duration = trip_local_merged['trav_time'].mean()  # convertir en minutes TO CHECK\n",
    "\n",
    "\n",
    "# Now, calculate the average_speed\n",
    "trip_local_merged['average_speed'] = (trip_local_merged['distance'] / 1000) / (trip_local_merged['trav_time'].dt.total_seconds() / 3600)\n",
    "\n",
    "# print(trip_local_merged.head(5)) # There is duplicates via the dep time or mode !!!\n",
    "\n",
    "average_distance = trip_local_merged['distance'].mean() / 1000  # convert to km\n",
    "overall_average_speed = trip_local_merged['average_speed'].mean()\n",
    "\n",
    "print(f\"Average durations of trips in {LOCAL} : {average_duration}m\")\n",
    "print(\"Average Distance: {:.2f} km\".format(average_distance))\n",
    "print(\"Overall Average Speed: {:.2f} km/h\".format(overall_average_speed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_facilities_df = activity_local_filtered[activity_local_filtered['type'] == 'work'][['id', 'facility', 'x', 'y']].drop_duplicates() # verifier via les homes\n",
    "population_local_merged = population_local.merge(work_facilities_df, on='id', how='left')\n",
    "population_local_merged.rename(columns={'facility': 'work_facility', 'x': 'work_facility_x', 'y': 'work_facility_y'}, inplace=True)\n",
    "\n",
    "population_local_merged.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_a1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
