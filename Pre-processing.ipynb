{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = 'Avenches'\n",
    "# LOCAL = 'Lausanne'\n",
    "FRACT_ACT = 0.02\n",
    "FRACT_POP = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(df, column, fraction):\n",
    "    \"\"\"\n",
    "    Perform stratified sampling on df based on column.\n",
    "    :param df: Input dataframe\n",
    "    :param column: Column name for stratification\n",
    "    :param fraction: Fraction of rows to sample from each group\n",
    "    :return: Sampled dataframe\n",
    "    \"\"\"\n",
    "    return df.groupby(column).apply(lambda x: x.sample(frac=fraction)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_horizon(t):\n",
    "    \"\"\" Help to round a time to 5m intervals \"\"\"\n",
    "    # Convert datetime.time to datetime.datetime for calculations\n",
    "    dt = datetime.combine(datetime.today(), t)\n",
    "    \n",
    "    # Find the number of seconds since midnight\n",
    "    seconds_since_midnight = (dt - dt.replace(hour=0, minute=0, second=0, microsecond=0)).seconds\n",
    "\n",
    "    # Round to the closest 5 minutes (300 seconds)\n",
    "    rounded_seconds = round(seconds_since_midnight / 300) * 300\n",
    "    rounded_dt = dt.replace(hour=0, minute=0, second=0) + timedelta(seconds=rounded_seconds)\n",
    "\n",
    "    return rounded_dt.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_horizon_interval(t):\n",
    "    \"\"\" Return time horizon corresponding to a timestamp \"\"\"\n",
    "    rounded_time = round_to_horizon(t)\n",
    "    \n",
    "    # Convert datetime.time to datetime.datetime for calculations\n",
    "    dt = datetime.combine(datetime.today(), rounded_time)\n",
    "    \n",
    "    # Get total minutes since midnight\n",
    "    minutes_since_midnight = (dt - dt.replace(hour=0, minute=0, second=0)).seconds // 60\n",
    "\n",
    "    # Convert total minutes to horizon intervals (5 minute intervals)\n",
    "    horizon_interval = minutes_since_midnight // 5\n",
    "\n",
    "    return horizon_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time(value):\n",
    "    \"\"\" Check that all time values are correct (hours<24)\"\"\"\n",
    "    try:\n",
    "        # Try converting the value to datetime and extract the time\n",
    "        return pd.to_datetime(value).time()\n",
    "    except:\n",
    "        # Return a placeholder for out-of-range values\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preferences(id, type, df):\n",
    "    ''' Returns the duration and starting preference for an individual and an activity'''\n",
    "    row = df.loc[(df['id'] == id) & (df['type'] == type)]\n",
    "    \n",
    "    if row.empty:\n",
    "        return default_durations[type], default_starting[type]\n",
    "    else:\n",
    "        # Assuming there's only one matching row, so taking the first one\n",
    "        duration = row['duration_interval'].iloc[0]\n",
    "        starting_time = row['start_time_interval'].iloc[0]\n",
    "        return duration, starting_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data and filter the irrelevants columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_file = 'Data/Original/vaud_activities.csv.gz'\n",
    "population_file = 'Data/Original/vaud_population.csv.gz'\n",
    "trip_file = 'Data/Original/vaud_trips.csv.gz'\n",
    "\n",
    "def read_gzipped_csv(file_path):\n",
    "    with gzip.open(file_path, 'rt') as file:\n",
    "        df = pd.read_csv(file)\n",
    "    return df\n",
    "\n",
    "activity_vaud = read_gzipped_csv(activity_file)\n",
    "population_vaud = read_gzipped_csv(population_file)[['id', 'home_x', 'home_y', 'local']]\n",
    "# trip_vaud = read_gzipped_csv(trip_file)[['Unnamed: 0', 'id', 'mode', 'dep_time','trav_time','start_link','end_link']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the population by the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_local = population_vaud[population_vaud['local'] == LOCAL] \n",
    "# print(len(population_local))\n",
    "# population_local.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the filtered population to extract activities of the same city. Also count the activities by type in this city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_local_ids = population_local['id'].unique()\n",
    "activity_local = activity_vaud[activity_vaud['id'].isin(population_local_ids)]\n",
    "activity_local_filt = activity_local[~activity_local['type'].isin(['other', 'pt interaction', 'home'])] \n",
    "activity_local_filt_nowork = activity_local[~activity_local['type'].isin(['other', 'pt interaction', 'home', 'work'])] \n",
    "# count_act_by_types = activity_local_filt.groupby('type')['facility'].nunique().reset_index()\n",
    "# print(f\"Here's the count of facilities by types in {LOCAL} : {count_act_by_types}\")\n",
    "# print(len(activity_local_filt))\n",
    "# activity_local_filt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the activities of this city by keeping the proportion between each type (stratified sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peut etre associer un seed pour avoir toujours le meme resultat ? \n",
    "# Attention : stratified sampling != proportional sampling \n",
    "activity_local_filt_sampled = stratified_sample(activity_local_filt_nowork, column='type', fraction=FRACT_ACT) # 0.001 to compare exact / heuristic\n",
    "# activity_local_filt_sampled.drop(columns=['start_time', 'end_time'], inplace=True)\n",
    "# print(len(activity_local_filt))\n",
    "# print(len(activity_local_filt_sampled))\n",
    "# count_act_by_types_sampled = activity_local_filt_sampled.groupby('type')['facility'].nunique().reset_index()\n",
    "# print(f\"Here's the count of facilities by types in the sample : {count_act_by_types_sampled}\")\n",
    "# activity_local_filt_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new columns for each activity with their caracterics (anticipate initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = 00:00 // 288 = 24:00 (total len = 289)\n",
    "# Code to fix the following values for each activity type : \n",
    "    # t1 = earliest time to start\n",
    "    # t2 = latest time to start\n",
    "    # t3 = max duration\n",
    "    # min duration\n",
    "    # des duration\n",
    "\n",
    "for i, row in activity_local_filt_sampled.iterrows():\n",
    "    type_ = row['type']\n",
    "    match type_: \n",
    "        case 'education':\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 1\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 84 # 7h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 276 # 23h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 132 # 11h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 6 # 30m\n",
    "        case 'leisure':\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 3\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 0 # 0h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 276 # 23h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 132 # 11h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 6 # 30m\n",
    "        case 'shop':\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 4\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 84 # 7h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 240 # 20h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 132 # 11h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 6 # 30m\n",
    "            \n",
    "int_columns = ['earliest_start', 'latest_start', 'max_duration', 'min_duration', 'x', 'y', 'group']\n",
    "activity_local_filt_sampled[int_columns] = activity_local_filt_sampled[int_columns].astype(int) \n",
    "\n",
    "# Proof that we have a activity id : \n",
    "# print(len(activity_local_filt_sampled))\n",
    "# print(activity_local_filt_sampled.index.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the individuals among the city inhabitants and converts home coordinates in `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_local_sample = population_local.sample(frac = FRACT_POP)\n",
    "int_columns_2 = ['home_x', 'home_y'] \n",
    "population_local_sample[int_columns_2] = population_local_sample[int_columns_2].astype(int) \n",
    "# print(len(population_local))\n",
    "# print(len(population_local_sample))\n",
    "# population_local_sample.head(1)\n",
    "# activity_local_filt_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter invalid times (hours < 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'start_time' and 'end_time' are in a format recognized by pandas (like 'HH:MM:SS')\n",
    "activity_local_filt['start_time'] = pd.to_timedelta(activity_local_filt['start_time'].astype(str))\n",
    "activity_local_filt['end_time'] = pd.to_timedelta(activity_local_filt['end_time'].astype(str))\n",
    "\n",
    "# Filter out any NaT values or times that are not within the correct range\n",
    "# For example, checking that 'start_time' and 'end_time' are less than 24 hours\n",
    "activity_local_filt = activity_local_filt[\n",
    "    (activity_local_filt['start_time'] < pd.Timedelta('1 days')) &\n",
    "    (activity_local_filt['end_time'] < pd.Timedelta('1 days'))\n",
    "]\n",
    "\n",
    "# Convert 'start_time' and 'end_time' to 'datetime.time' if they are within a single day.\n",
    "activity_local_filt['start_time'] = activity_local_filt['start_time'].apply(\n",
    "    lambda x: (datetime.min + x).time() if isinstance(x, pd.Timedelta) and x < pd.Timedelta(days=1) else x\n",
    ")\n",
    "activity_local_filt['end_time'] = activity_local_filt['end_time'].apply(\n",
    "    lambda x: (datetime.min + x).time() if isinstance(x, pd.Timedelta) and x < pd.Timedelta(days=1) else x\n",
    ")\n",
    "\n",
    "# print(len(activity_local_filt))\n",
    "# activity_local_filt.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert time object in terms of horizons  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_local_filt['start_time_interval'] = activity_local_filt['start_time'].apply(time_to_horizon_interval)\n",
    "activity_local_filt['end_time_interval'] = activity_local_filt['end_time'].apply(time_to_horizon_interval)\n",
    "activity_local_filt['duration_interval'] = activity_local_filt['end_time_interval'] - activity_local_filt['start_time_interval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each individual, and for each activity type, add starting time and duration preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity_local_filt.head()\n",
    "# population_local_sample.head()\n",
    "rows_of_interessed = activity_local_filt[activity_local_filt['id'].isin(population_local_sample['id'])]\n",
    "# rows_of_interessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valeurs par default : c'est facile de faire la moyenne des time horizon pour type (starting et duration) !\n",
    "# default_durations = {'shop': 216, 'leisure': 216, 'work': 108, 'education': 108}\n",
    "# default_starting = {'shop': 12, 'leisure': 12, 'work': 48, 'education': 48}\n",
    "# default_durations = {'shop': 0, 'leisure': 0, 'work': 0, 'education': 0}\n",
    "# default_starting = {'shop': 0, 'leisure': 0, 'work': 0, 'education': 0}\n",
    "\n",
    "default_durations = {}\n",
    "default_starting = {}\n",
    "facility_types = ['shop', 'leisure', 'education', 'work']\n",
    "for facility in facility_types: \n",
    "    temp_df = activity_local_filt[activity_local_filt['type'] == facility]\n",
    "    default_durations[facility] = int(np.floor(temp_df['duration_interval'].mean()))\n",
    "    default_starting[facility] = int(np.floor(temp_df['start_time_interval'].mean()))\n",
    "    \n",
    "# print(default_starting)\n",
    "# print(default_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preferences(id, type, df):\n",
    "    ''' Returns the duration and starting preference for an individual and an activity\n",
    "    Returns default value for each activity that the individual didn't do'''\n",
    "    row = df.loc[(df['id'] == id) & (df['type'] == type)]\n",
    "    \n",
    "    if row.empty:\n",
    "        return default_durations[type], default_starting[type], 0\n",
    "    else:\n",
    "        # Assuming there's only one matching row, so taking the first one\n",
    "        duration = row['duration_interval'].iloc[0]\n",
    "        starting_time = row['start_time_interval'].iloc[0]\n",
    "        return duration, starting_time, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.42it/s]\n"
     ]
    }
   ],
   "source": [
    "facility_types = ['shop', 'leisure', 'education', 'work']\n",
    "for facility in tqdm(facility_types): \n",
    "    \n",
    "    # function extracts both duration and starting time preferences and assigns them\n",
    "    preferences = population_local_sample.apply(\n",
    "        lambda row: get_preferences(row['id'], facility, rows_of_interessed), axis=1\n",
    "    )\n",
    "    \n",
    "    population_local_sample[f'{facility}_duration'] = preferences.apply(lambda x: x[0])\n",
    "    population_local_sample[f'{facility}_starting'] = preferences.apply(lambda x: x[1])\n",
    "    population_local_sample[f'{facility}_participation'] = preferences.apply(lambda x: x[2])\n",
    "\n",
    "# population_local_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 791 work facilities in Avenches\n"
     ]
    }
   ],
   "source": [
    "df_work_facilities = activity_local[activity_local['type'] == 'work']\n",
    "print(f\"There are {df_work_facilities['facility'].nunique()} work facilities in {LOCAL}\")\n",
    "work_facilities_count = df_work_facilities.groupby('facility')['id'].count()\n",
    "\n",
    "# Créer un DataFrame résumé avec les coordonnées moyennes pour chaque établissement\n",
    "facility_coords = df_work_facilities.groupby('facility')[['x', 'y']].mean()\n",
    "\n",
    "# Créer le dictionnaire pour les coordonnées x et y des établissements\n",
    "facility_coords_dict = facility_coords.to_dict('index')\n",
    "\n",
    "# Choisir un établissement pour chaque individu dans l'échantillon\n",
    "N = len(population_local_sample)\n",
    "facilities = work_facilities_count.index.tolist()\n",
    "workers = work_facilities_count.tolist()\n",
    "chosen_facilities = random.choices(facilities, weights=workers, k=N)\n",
    "\n",
    "# Assigner les coordonnées x, y et l'ID de l'établissement choisi\n",
    "population_local_sample['work_x'] = [int(facility_coords_dict[facility]['x']) for facility in chosen_facilities]\n",
    "population_local_sample['work_y'] = [int(facility_coords_dict[facility]['y']) for facility in chosen_facilities]\n",
    "population_local_sample['work_id'] = chosen_facilities\n",
    "# population_local_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the final preprocessed dataframes into .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_local_filt_sampled.to_csv(f'Data/PreProcessed/activity.csv', index=False)\n",
    "population_local_sample.to_csv(f'Data/PreProcessed/population.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_a1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
